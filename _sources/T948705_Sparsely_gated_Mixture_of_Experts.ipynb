{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy2u5YZVej_A"
      },
      "source": [
        "# Sparsely-gated Mixture-of-Experts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-RQWsJQc7GF"
      },
      "source": [
        "<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bc27926b-46a1-4699-b456-d439f3484256/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211027%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211027T062821Z&X-Amz-Expires=86400&X-Amz-Signature=01ec9e3caff091d3c6f2289e1c1963dbec4f638a7753a142d15461954dc9e237&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'></center></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FftlGp1Nk7ZM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C74UBefepVZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import Adam\n",
        "import torchvision.transforms as transforms\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBtgh1Nzk3_c"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MZwEQz7te7cs"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.log_soft = nn.LogSoftmax(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.log_soft(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AlmLcwywezkH"
      },
      "outputs": [],
      "source": [
        "class SparseDispatcher(object):\n",
        "    \"\"\"Helper for implementing a mixture of experts.\n",
        "    The purpose of this class is to create input minibatches for the\n",
        "    experts and to combine the results of the experts to form a unified\n",
        "    output tensor.\n",
        "    There are two functions:\n",
        "    dispatch - take an input Tensor and create input Tensors for each expert.\n",
        "    combine - take output Tensors from each expert and form a combined output\n",
        "      Tensor.  Outputs from different experts for the same batch element are\n",
        "      summed together, weighted by the provided \"gates\".\n",
        "    The class is initialized with a \"gates\" Tensor, which specifies which\n",
        "    batch elements go to which experts, and the weights to use when combining\n",
        "    the outputs.  Batch element b is sent to expert e iff gates[b, e] != 0.\n",
        "    The inputs and outputs are all two-dimensional [batch, depth].\n",
        "    Caller is responsible for collapsing additional dimensions prior to\n",
        "    calling this class and reshaping the output to the original shape.\n",
        "    See common_layers.reshape_like().\n",
        "    Example use:\n",
        "    gates: a float32 `Tensor` with shape `[batch_size, num_experts]`\n",
        "    inputs: a float32 `Tensor` with shape `[batch_size, input_size]`\n",
        "    experts: a list of length `num_experts` containing sub-networks.\n",
        "    dispatcher = SparseDispatcher(num_experts, gates)\n",
        "    expert_inputs = dispatcher.dispatch(inputs)\n",
        "    expert_outputs = [experts[i](expert_inputs[i]) for i in range(num_experts)]\n",
        "    outputs = dispatcher.combine(expert_outputs)\n",
        "    The preceding code sets the output for a particular example b to:\n",
        "    output[b] = Sum_i(gates[b, i] * experts[i](inputs[b]))\n",
        "    This class takes advantage of sparsity in the gate matrix by including in the\n",
        "    `Tensor`s for expert i only the batch elements for which `gates[b, i] > 0`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_experts, gates):\n",
        "        \"\"\"Create a SparseDispatcher.\"\"\"\n",
        "\n",
        "        self._gates = gates\n",
        "        self._num_experts = num_experts\n",
        "        # sort experts\n",
        "        sorted_experts, index_sorted_experts = torch.nonzero(gates).sort(0)\n",
        "        # drop indices\n",
        "        _, self._expert_index = sorted_experts.split(1, dim=1)\n",
        "        # get according batch index for each expert\n",
        "        self._batch_index = sorted_experts[index_sorted_experts[:, 1],0]\n",
        "        # calculate num samples that each expert gets\n",
        "        self._part_sizes = list((gates > 0).sum(0).numpy())\n",
        "        # expand gates to match with self._batch_index\n",
        "        gates_exp = gates[self._batch_index.flatten()]\n",
        "        self._nonzero_gates = torch.gather(gates_exp, 1, self._expert_index)\n",
        "\n",
        "    def dispatch(self, inp):\n",
        "        \"\"\"Create one input Tensor for each expert.\n",
        "        The `Tensor` for a expert `i` contains the slices of `inp` corresponding\n",
        "        to the batch elements `b` where `gates[b, i] > 0`.\n",
        "        Args:\n",
        "          inp: a `Tensor` of shape \"[batch_size, <extra_input_dims>]`\n",
        "        Returns:\n",
        "          a list of `num_experts` `Tensor`s with shapes\n",
        "            `[expert_batch_size_i, <extra_input_dims>]`.\n",
        "        \"\"\"\n",
        "\n",
        "        # assigns samples to experts whose gate is nonzero\n",
        "\n",
        "        # expand according to batch index so we can just split by _part_sizes\n",
        "        inp_exp = inp[self._batch_index].squeeze(1)\n",
        "        return torch.split(inp_exp, self._part_sizes, dim=0)\n",
        "\n",
        "\n",
        "    def combine(self, expert_out, multiply_by_gates=True):\n",
        "        \"\"\"Sum together the expert output, weighted by the gates.\n",
        "        The slice corresponding to a particular batch element `b` is computed\n",
        "        as the sum over all experts `i` of the expert output, weighted by the\n",
        "        corresponding gate values.  If `multiply_by_gates` is set to False, the\n",
        "        gate values are ignored.\n",
        "        Args:\n",
        "          expert_out: a list of `num_experts` `Tensor`s, each with shape\n",
        "            `[expert_batch_size_i, <extra_output_dims>]`.\n",
        "          multiply_by_gates: a boolean\n",
        "        Returns:\n",
        "          a `Tensor` with shape `[batch_size, <extra_output_dims>]`.\n",
        "        \"\"\"\n",
        "        # apply exp to expert outputs, so we are not longer in log space\n",
        "        stitched = torch.cat(expert_out, 0).exp()\n",
        "\n",
        "        if multiply_by_gates:\n",
        "            stitched = stitched.mul(self._nonzero_gates)\n",
        "        zeros = torch.zeros(self._gates.size(0), expert_out[-1].size(1), requires_grad=True)\n",
        "        # combine samples that have been processed by the same k experts\n",
        "        combined = zeros.index_add(0, self._batch_index, stitched.float())\n",
        "        # add eps to all zero values in order to avoid nans when going back to log space\n",
        "        combined[combined == 0] = np.finfo(float).eps\n",
        "        # back to log space\n",
        "        return combined.log()\n",
        "\n",
        "\n",
        "    def expert_to_gates(self):\n",
        "        \"\"\"Gate values corresponding to the examples in the per-expert `Tensor`s.\n",
        "        Returns:\n",
        "          a list of `num_experts` one-dimensional `Tensor`s with type `tf.float32`\n",
        "              and shapes `[expert_batch_size_i]`\n",
        "        \"\"\"\n",
        "        # split nonzero gates for each expert\n",
        "        return torch.split(self._nonzero_gates, self._part_sizes, dim=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MoE(nn.Module):\n",
        "\n",
        "    \"\"\"Call a Sparsely gated mixture of experts layer with 1-layer Feed-Forward networks as experts.\n",
        "    Args:\n",
        "    input_size: integer - size of the input\n",
        "    output_size: integer - size of the input\n",
        "    num_experts: an integer - number of experts\n",
        "    hidden_size: an integer - hidden size of the experts\n",
        "    noisy_gating: a boolean\n",
        "    k: an integer - how many experts to use for each batch element\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, output_size, num_experts, hidden_size, noisy_gating=True, k=4):\n",
        "        super(MoE, self).__init__()\n",
        "        self.noisy_gating = noisy_gating\n",
        "        self.num_experts = num_experts\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.k = k\n",
        "        # instantiate experts\n",
        "        self.experts = nn.ModuleList([MLP(self.input_size, self.output_size, self.hidden_size) for i in range(self.num_experts)])\n",
        "        self.w_gate = nn.Parameter(torch.zeros(input_size, num_experts), requires_grad=True)\n",
        "        self.w_noise = nn.Parameter(torch.zeros(input_size, num_experts), requires_grad=True)\n",
        "\n",
        "        self.softplus = nn.Softplus()\n",
        "        self.softmax = nn.Softmax(1)\n",
        "        self.normal = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
        "\n",
        "        assert(self.k <= self.num_experts)\n",
        "\n",
        "    def cv_squared(self, x):\n",
        "        \"\"\"The squared coefficient of variation of a sample.\n",
        "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
        "        Epsilons added for numerical stability.\n",
        "        Returns 0 for an empty Tensor.\n",
        "        Args:\n",
        "        x: a `Tensor`.\n",
        "        Returns:\n",
        "        a `Scalar`.\n",
        "        \"\"\"\n",
        "        eps = 1e-10\n",
        "        # if only num_experts = 1\n",
        "        if x.shape[0] == 1:\n",
        "            return torch.Tensor([0])\n",
        "        return x.float().var() / (x.float().mean()**2 + eps)\n",
        "\n",
        "\n",
        "    def _gates_to_load(self, gates):\n",
        "        \"\"\"Compute the true load per expert, given the gates.\n",
        "        The load is the number of examples for which the corresponding gate is >0.\n",
        "        Args:\n",
        "        gates: a `Tensor` of shape [batch_size, n]\n",
        "        Returns:\n",
        "        a float32 `Tensor` of shape [n]\n",
        "        \"\"\"\n",
        "        return (gates > 0).sum(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
        "        \"\"\"Helper function to NoisyTopKGating.\n",
        "        Computes the probability that value is in top k, given different random noise.\n",
        "        This gives us a way of backpropagating from a loss that balances the number\n",
        "        of times each expert is in the top k experts per example.\n",
        "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
        "        not be differentiable.\n",
        "        Args:\n",
        "        clean_values: a `Tensor` of shape [batch, n].\n",
        "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
        "          normally distributed noise with standard deviation noise_stddev.\n",
        "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
        "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
        "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
        "        Returns:\n",
        "        a `Tensor` of shape [batch, n].\n",
        "        \"\"\"\n",
        "\n",
        "        batch = clean_values.size(0)\n",
        "        m = noisy_top_values.size(1)\n",
        "        top_values_flat = noisy_top_values.flatten()\n",
        "        threshold_positions_if_in = torch.arange(batch) * m + self.k\n",
        "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
        "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
        "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
        "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat,0 , threshold_positions_if_out), 1)\n",
        "        # is each value currently in the top k.\n",
        "        prob_if_in = self.normal.cdf((clean_values - threshold_if_in)/noise_stddev)\n",
        "        prob_if_out = self.normal.cdf((clean_values - threshold_if_out)/noise_stddev)\n",
        "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
        "        return prob\n",
        "\n",
        "\n",
        "    def noisy_top_k_gating(self, x, train, noise_epsilon=1e-2):\n",
        "        \"\"\"Noisy top-k gating.\n",
        "          See paper: https://arxiv.org/abs/1701.06538.\n",
        "          Args:\n",
        "            x: input Tensor with shape [batch_size, input_size]\n",
        "            train: a boolean - we only add noise at training time.\n",
        "            noise_epsilon: a float\n",
        "          Returns:\n",
        "            gates: a Tensor with shape [batch_size, num_experts]\n",
        "            load: a Tensor with shape [num_experts]\n",
        "        \"\"\"\n",
        "        clean_logits = x @ self.w_gate\n",
        "        if self.noisy_gating:\n",
        "            raw_noise_stddev = x @ self.w_noise\n",
        "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon) * train)\n",
        "            noisy_logits = clean_logits + ( torch.randn_like(clean_logits) * noise_stddev)\n",
        "            logits = noisy_logits\n",
        "        else:\n",
        "            logits = clean_logits\n",
        "\n",
        "        # calculate topk + 1 that will be needed for the noisy gates\n",
        "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
        "        top_k_logits = top_logits[:, :self.k]\n",
        "        top_k_indices = top_indices[:, :self.k]\n",
        "        top_k_gates = self.softmax(top_k_logits)\n",
        "\n",
        "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
        "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
        "\n",
        "        if self.noisy_gating and self.k < self.num_experts:\n",
        "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
        "        else:\n",
        "            load = self._gates_to_load(gates)\n",
        "        return gates, load\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, train=True, loss_coef=1e-2):\n",
        "        \"\"\"Args:\n",
        "        x: tensor shape [batch_size, input_size]\n",
        "        train: a boolean scalar.\n",
        "        loss_coef: a scalar - multiplier on load-balancing losses\n",
        "        Returns:\n",
        "        y: a tensor with shape [batch_size, output_size].\n",
        "        extra_training_loss: a scalar.  This should be added into the overall\n",
        "        training loss of the model.  The backpropagation of this loss\n",
        "        encourages all experts to be approximately equally used across a batch.\n",
        "        \"\"\"\n",
        "        gates, load = self.noisy_top_k_gating(x, train)\n",
        "        # calculate importance loss\n",
        "        importance = gates.sum(0)\n",
        "        #\n",
        "        loss = self.cv_squared(importance) + self.cv_squared(load)\n",
        "        loss *= loss_coef\n",
        "\n",
        "        dispatcher = SparseDispatcher(self.num_experts, gates)\n",
        "        expert_inputs = dispatcher.dispatch(x)\n",
        "        gates = dispatcher.expert_to_gates()\n",
        "        expert_outputs = [self.experts[i](expert_inputs[i]) for i in range(self.num_experts)]\n",
        "        y = dispatcher.combine(expert_outputs)\n",
        "        return y, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RyYGM1Rfwco"
      },
      "source": [
        "## Dummy example\n",
        "\n",
        "a minimal working example illustrating how to train and evaluate the MoE layer with dummy inputs and targets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAprN9tbcZAl"
      },
      "source": [
        "> Note: If dummy example doesn't work, try in `torch==1.0.0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7VsrYAUcmih"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Results - loss: 3.01, aux_loss: 0.002\n",
            "Evaluation Results - loss: 3.00, aux_loss: 0.033\n"
          ]
        }
      ],
      "source": [
        "def train(x,y, model, loss_fn, optim):\n",
        "    # model returns the prediction and the loss that encourages all experts to have equal importance and load\n",
        "    y_hat, aux_loss = model(x.float())\n",
        "    # calculate prediction loss\n",
        "    loss = loss_fn(y_hat, y)\n",
        "    # combine losses\n",
        "    total_loss = loss + aux_loss\n",
        "    optim.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    print(\"Training Results - loss: {:.2f}, aux_loss: {:.3f}\".format(loss.item(), aux_loss.item()))\n",
        "    return model\n",
        "\n",
        "def eval(x, y, model, loss_fn):\n",
        "    model.eval()\n",
        "    # model returns the prediction and the loss that encourages all experts to have equal importance and load\n",
        "    y_hat, aux_loss = model(x.float(), train=False)\n",
        "    loss = loss_fn(y_hat, y)\n",
        "    total_loss = loss + aux_loss\n",
        "    print(\"Evaluation Results - loss: {:.2f}, aux_loss: {:.3f}\".format(loss.item(), aux_loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "def dummy_data(batch_size, input_size, num_classes):\n",
        "    # dummy input\n",
        "    x = torch.rand(batch_size, input_size)\n",
        "\n",
        "    # dummy target\n",
        "    y = torch.randint(num_classes, (batch_size, 1)).squeeze(1)\n",
        "    return x,y\n",
        "\n",
        "\n",
        "# arguments\n",
        "input_size = 1000\n",
        "num_classes = 20\n",
        "num_experts = 10\n",
        "hidden_size = 64\n",
        "batch_size = 5\n",
        "k = 4\n",
        "\n",
        "# instantiate the MoE layer\n",
        "model = MoE(input_size, num_classes, num_experts,hidden_size, k=k, noisy_gating=True)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "optim = Adam(model.parameters())\n",
        "\n",
        "x, y = dummy_data(batch_size, input_size, num_classes)\n",
        "\n",
        "# train\n",
        "model = train(x, y, model, loss_fn, optim)\n",
        "# evaluate\n",
        "x, y = dummy_data(batch_size, input_size, num_classes)\n",
        "eval(x, y, model, loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFG0tXWOf2AQ"
      },
      "source": [
        "## CIFAR-10 example\n",
        "\n",
        "a minimal working example of the CIFAR 10 dataset. It achieves an accuracy of 39% with arbitrary hyper-parameters and not fully converged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL_yIDpxfBzT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a14a77a376b4892ad2ccbba543aeac1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "[1,   100] loss: 2.284\n",
            "[1,   200] loss: 2.229\n",
            "[1,   300] loss: 2.154\n",
            "[1,   400] loss: 2.089\n",
            "[1,   500] loss: 2.056\n",
            "[1,   600] loss: 1.999\n",
            "[1,   700] loss: 1.958\n",
            "[2,   100] loss: 1.898\n",
            "[2,   200] loss: 1.865\n",
            "[2,   300] loss: 1.859\n",
            "[2,   400] loss: 1.829\n",
            "[2,   500] loss: 1.798\n",
            "[2,   600] loss: 1.789\n",
            "[2,   700] loss: 1.761\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 39 %\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "device = torch.device('cpu')\n",
        "net = MoE(input_size=3072,output_size= 10, num_experts=10, hidden_size=256, noisy_gating=True, k=4)\n",
        "net = net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs, aux_loss = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss = loss + aux_loss\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs, _ = net(images.view(images.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "T948705_Sparsely_gated_Mixture_of_Experts.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
