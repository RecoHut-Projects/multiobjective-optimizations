
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multi-Task Recommender on Olist dataset using TFRS Library &#8212; multiobjective-optimizations</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MAMO Framework" href="T671443_MAMO_Framework.html" />
    <link rel="prev" title="Multi-task Learning on ML-100k in TFRS" href="T559084_Multi_task_Learning_on_ML_100k_in_TFRS.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">multiobjective-optimizations</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L069335_Multi_Objective_Optimization.html">
   Multi-Objective Optimization
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Concepts
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L492548_Efficient_Frontier.html">
   Efficient Frontier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L839342_Pareto_Optimality.html">
   Pareto Optimality
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L483593_MOO_Decision_Maker.html">
   MOO Decision Maker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L336869_Multi_Task_Learning.html">
   Multi-Task Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L553498_MOO_in_Recommender_Systems.html">
   MOO in Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L480379_Marketplace_Recommenders.html">
   Marketplace Recommenders
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L556513_Multi_Objective_Hyperparameter_Optimization.html">
   Multi-Objective Hyperparameter Optimization
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L005003_Scalarization.html">
   Scalarization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L762719_Shared_Bottom.html">
   Shared Bottom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L915313_Expected_Hypervolume_Improvement_%28EHVI%29.html">
   Expected Hypervolume Improvement (EHVI)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L587138_Multi_gradient_Descent_%28MGDRec%29.html">
   Multi-gradient Descent (MGDRec)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L861465_Mixture_of_Experts_%28MoE%29.html">
   Mixture of Experts (MoE)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L485744_Multi_gate_Mixture_of_Experts_%28MMoE%29.html">
   Multi-gate Mixture-of-Experts (MMoE)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L519476_Entire_Space_Multi_Task_Model_%28ESSM%29.html">
   Entire Space Multi-Task Model (ESSM)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L718205_Progressive_Layered_Extraction_%28PLE%29.html">
   Progressive Layered Extraction (PLE)
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Cases
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L749932_MTL_for_Related_Products_Recommendations_at_Pinterest.html">
   MTL for Related Products Recommendations at Pinterest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L792752_UberEats.html">
   UberEats
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L106645_Etsy.html">
   Etsy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L149938_Airbnb_Experiences.html">
   Airbnb Experiences
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="T929652_Efficient_Frontier.html">
   Efficient Frontier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T854417_Linear_Optimization_with_OR_Tools.html">
   Linear Optimization with OR-Tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T209908_Stein%27s_Paradox.html">
   Steinâ€™s Paradox
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T423887_Solving_MOO_with_SMT_Toolkit.html">
   Solving MOO with SMT Toolkit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T277640_Efficient_Continuous_Pareto_Exploration_in_MTL_on_UCI_Census.html">
   Efficient Continuous Pareto Exploration in MTL on UCI Census
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T851476_Multi_Task_Learning.html">
   Multi-Task Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T307666_Pareto_Efficient_algorithm_for_MOO.html">
   Pareto-Efficient algorithm for MOO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T465017_Shared_Bottom_in_Tensorflow.html">
   Shared Bottom in Tensorflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T175823_MoE_in_Tensorflow.html">
   MoE in Tensorflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T580632_MMoE_on_Census_income_data_in_Tensorflow.html">
   MMoE on Census income data in Tensorflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T948705_Sparsely_gated_Mixture_of_Experts.html">
   Sparsely-gated Mixture-of-Experts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T458949_Multi_Objective_Ranking_using_Constrained_Optimization_in_GBTs.html">
   Multi-Objective Ranking using Constrained Optimization in GBTs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T145475_Multi_objective_Optimization_using_Pymoo_Library.html">
   Multi-objective Optimization using Pymoo Library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T892775_Exploring_Multi_Objective_Hyperparameter_Optimization.html">
   Exploring Multi-Objective Hyperparameter Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T660394_Implicit_Hybrid_Movie_Recommender_using_Collie_Library.html">
   Implicit Hybrid Movie Recommender using Collie Library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T559084_Multi_task_Learning_on_ML_100k_in_TFRS.html">
   Multi-task Learning on ML-100k in TFRS
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Multi-Task Recommender on Olist dataset using TFRS Library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T671443_MAMO_Framework.html">
   MAMO Framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T952247_MKR.html">
   MKR
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/T368830_Multi_Task_Recommender_on_Olist_dataset_using_TFRS_Library.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/multiobjective-optimizations/main?urlpath=tree/docs/T368830_Multi_Task_Recommender_on_Olist_dataset_using_TFRS_Library.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/sparsh-ai/multiobjective-optimizations/blob/main/docs/T368830_Multi_Task_Recommender_on_Olist_dataset_using_TFRS_Library.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     Overview
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#theory">
     Theory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#outline">
     Outline
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-loading">
   Data Loading
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   Data Preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#retrieval-model">
   Retrieval Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ranking-model">
   Ranking Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adding-context">
   Adding Context
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multi-task-model-with-relu-based-dnn">
   Multi-Task Model with ReLU-based DNN
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rating-specialized-model">
     Rating-specialized model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#retrieval-specialized-model">
     Retrieval-specialized model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#joint-model">
     Joint model
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="multi-task-recommender-on-olist-dataset-using-tfrs-library">
<h1>Multi-Task Recommender on Olist dataset using TFRS Library<a class="headerlink" href="#multi-task-recommender-on-olist-dataset-using-tfrs-library" title="Permalink to this headline">Â¶</a></h1>
<blockquote>
<div><p>TFRS Retrieval, ranking, time and text feature embeddings, and multi-task modeling on Olist retail dataset.</p>
</div></blockquote>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>Objective: To demonstrate TensorFlow 2.0 TFRS recommenders library to build a recommendation system on a customer retail data.</p></li>
<li><p>Data source: <a class="reference external" href="https://www.kaggle.com/olistbr/brazilian-ecommerce/home/">https://www.kaggle.com/olistbr/brazilian-ecommerce/home/</a></p></li>
<li><p>Benefit: Flexible model, ability to add different features and specify and adjust model complexity easily.</p></li>
</ul>
</div>
<div class="section" id="theory">
<h3>Theory<a class="headerlink" href="#theory" title="Permalink to this headline">Â¶</a></h3>
<p>Two types of recommendation modelâ€“ Retrieval and Ranking.</p>
<ul class="simple">
<li><p>Retrieval: The retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient. Retrieval can be computationally more efficient because it only returns smaller set of items a user would strongly interested.</p></li>
<li><p>Ranking: The ranking stage takes the outputs of the retrieval model and fine-tunes them to select the best possible handful of recommendations. Its task is to narrow down the set of items the user may be interested in to a shortlist of likely candidates.</p></li>
</ul>
<p>Built with TensorFlow 2.x, TFRS makes it possible to:</p>
<ul class="simple">
<li><p>Build and evaluate flexibleÂ <strong><a class="reference external" href="https://research.google/pubs/pub48840/">candidate nomination models</a></strong>;</p></li>
<li><p>Freely incorporate item, user, and contextÂ <strong><a class="reference external" href="https://tensorflow.org/recommenders/examples/featurization">information</a></strong>Â into recommendation models;</p></li>
<li><p>TrainÂ <strong><a class="reference external" href="https://tensorflow.org/recommenders/examples/multitask">multi-task models</a></strong>Â that jointly optimize multiple recommendation objectives;</p></li>
<li><p>Efficiently serve the resulting models usingÂ <strong><a class="reference external" href="https://www.tensorflow.org/tfx/guide/serving">TensorFlow Serving</a></strong>.</p></li>
<li><p><a class="reference external" href="https://research.google/pubs/pub47842/">Multi-task learning</a>, <a class="reference external" href="https://arxiv.org/abs/1708.05123">feature cross modeling</a>, <a class="reference external" href="https://arxiv.org/abs/2007.12865">self-supervised learning</a>, and state-of-the-art efficient <a class="reference external" href="https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html">approximate nearest neighbours computation</a>.</p></li>
</ul>
</div>
<div class="section" id="outline">
<h3>Outline<a class="headerlink" href="#outline" title="Permalink to this headline">Â¶</a></h3>
<ol class="simple">
<li><p>Retrieval model</p></li>
<li><p>Ranking model</p></li>
<li><p>Adding text and timestamp embedding</p></li>
<li><p>Multitask recommendation, combining retrieval and ranking</p></li>
<li><p>Add more features using Cross Network.</p></li>
</ol>
</div>
</div>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install -q tensorflow-recommenders
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>?25l
     |â–ˆâ–ˆâ–ˆâ–‰                            | 10 kB 21.2 MB/s eta 0:00:01
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 20 kB 24.3 MB/s eta 0:00:01
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 30 kB 12.2 MB/s eta 0:00:01
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 40 kB 9.5 MB/s eta 0:00:01
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 51 kB 5.2 MB/s eta 0:00:01
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 61 kB 5.6 MB/s eta 0:00:01
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 71 kB 5.9 MB/s eta 0:00:01
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 81 kB 6.5 MB/s eta 0:00:01
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85 kB 2.5 MB/s 
?25h
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pprint</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Text</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_recommenders</span> <span class="k">as</span> <span class="nn">tfrs</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install -q watermark
%reload_ext watermark
%watermark -m -iv -u -t -d
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Last updated: 2021-10-27 05:45:19

Compiler    : GCC 7.5.0
OS          : Linux
Release     : 5.4.104+
Machine     : x86_64
Processor   : x86_64
CPU cores   : 2
Architecture: 64bit

seaborn                : 0.11.2
pandas                 : 1.1.5
numpy                  : 1.19.5
matplotlib             : 3.2.2
tensorflow_recommenders: 0.6.0
IPython                : 5.5.0
tensorflow             : 2.6.0
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-loading">
<h2>Data Loading<a class="headerlink" href="#data-loading" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># !pip install -q -U kaggle</span>
<span class="c1"># !pip install --upgrade --force-reinstall --no-deps kaggle</span>
<span class="c1"># !mkdir ~/.kaggle</span>
<span class="c1"># !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/</span>
<span class="c1"># !chmod 600 ~/.kaggle/kaggle.json</span>
<span class="c1"># !kaggle datasets download -d olistbr/brazilian-ecommerce</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!git clone -q https://github.com/sparsh-ai/multiobjective-optimizations.git
!cp multiobjective-optimizations/data/brazilian-ecommerce.zip .
!unzip brazilian-ecommerce.zip
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Archive:  brazilian-ecommerce.zip
  inflating: olist_customers_dataset.csv  
  inflating: olist_geolocation_dataset.csv  
  inflating: olist_order_items_dataset.csv  
  inflating: olist_order_payments_dataset.csv  
  inflating: olist_order_reviews_dataset.csv  
  inflating: olist_orders_dataset.csv  
  inflating: olist_products_dataset.csv  
  inflating: olist_sellers_dataset.csv  
  inflating: product_category_name_translation.csv  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">glob</span>
<span class="n">files</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;/content/*.csv&#39;</span><span class="p">))</span>
<span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">files</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dfs</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">dfs </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">files</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">display</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 0: olist_customers_dataset
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_id</th>
      <th>customer_unique_id</th>
      <th>customer_zip_code_prefix</th>
      <th>customer_city</th>
      <th>customer_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>
      <td>861eff4711a542e4b93843c6dd7febb0</td>
      <td>14409</td>
      <td>franca</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18955e83d337fd6b2def6b18a428ac77</td>
      <td>290c77bc529b7ac935b93aa66c333dc3</td>
      <td>9790</td>
      <td>sao bernardo do campo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4e7b3e00288586ebd08712fdd0374a03</td>
      <td>060e732b5b29e8181a18229c7b0b2b5e</td>
      <td>1151</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>
      <td>259dac757896d24d7702b9acbbff3f3c</td>
      <td>8775</td>
      <td>mogi das cruzes</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>
      <td>345ecd01c38d18a9036ed96c73b8d066</td>
      <td>13056</td>
      <td>campinas</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 1: olist_geolocation_dataset
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geolocation_zip_code_prefix</th>
      <th>geolocation_lat</th>
      <th>geolocation_lng</th>
      <th>geolocation_city</th>
      <th>geolocation_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1037</td>
      <td>-23.545621</td>
      <td>-46.639292</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1046</td>
      <td>-23.546081</td>
      <td>-46.644820</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1046</td>
      <td>-23.546129</td>
      <td>-46.642951</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1041</td>
      <td>-23.544392</td>
      <td>-46.639499</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1035</td>
      <td>-23.541578</td>
      <td>-46.641607</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 2: olist_order_items_dataset
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>order_item_id</th>
      <th>product_id</th>
      <th>seller_id</th>
      <th>shipping_limit_date</th>
      <th>price</th>
      <th>freight_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>00010242fe8c5a6d1ba2dd792cb16214</td>
      <td>1</td>
      <td>4244733e06e7ecb4970a6e2683c13e61</td>
      <td>48436dade18ac8b2bce089ec2a041202</td>
      <td>2017-09-19 09:45:35</td>
      <td>58.90</td>
      <td>13.29</td>
    </tr>
    <tr>
      <th>1</th>
      <td>00018f77f2f0320c557190d7a144bdd3</td>
      <td>1</td>
      <td>e5f2d52b802189ee658865ca93d83a8f</td>
      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>
      <td>2017-05-03 11:05:13</td>
      <td>239.90</td>
      <td>19.93</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000229ec398224ef6ca0657da4fc703e</td>
      <td>1</td>
      <td>c777355d18b72b67abbeef9df44fd0fd</td>
      <td>5b51032eddd242adc84c38acab88f23d</td>
      <td>2018-01-18 14:48:30</td>
      <td>199.00</td>
      <td>17.87</td>
    </tr>
    <tr>
      <th>3</th>
      <td>00024acbcdf0a6daa1e931b038114c75</td>
      <td>1</td>
      <td>7634da152a4610f1595efa32f14722fc</td>
      <td>9d7a1d34a5052409006425275ba1c2b4</td>
      <td>2018-08-15 10:10:18</td>
      <td>12.99</td>
      <td>12.79</td>
    </tr>
    <tr>
      <th>4</th>
      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>
      <td>1</td>
      <td>ac6c3623068f30de03045865e4e10089</td>
      <td>df560393f3a51e74553ab94004ba5c87</td>
      <td>2017-02-13 13:57:51</td>
      <td>199.90</td>
      <td>18.14</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 3: olist_order_payments_dataset
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>payment_sequential</th>
      <th>payment_type</th>
      <th>payment_installments</th>
      <th>payment_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b81ef226f3fe1789b1e8b2acac839d17</td>
      <td>1</td>
      <td>credit_card</td>
      <td>8</td>
      <td>99.33</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a9810da82917af2d9aefd1278f1dcfa0</td>
      <td>1</td>
      <td>credit_card</td>
      <td>1</td>
      <td>24.39</td>
    </tr>
    <tr>
      <th>2</th>
      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>
      <td>1</td>
      <td>credit_card</td>
      <td>1</td>
      <td>65.71</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ba78997921bbcdc1373bb41e913ab953</td>
      <td>1</td>
      <td>credit_card</td>
      <td>8</td>
      <td>107.78</td>
    </tr>
    <tr>
      <th>4</th>
      <td>42fdf880ba16b47b59251dd489d4441a</td>
      <td>1</td>
      <td>credit_card</td>
      <td>2</td>
      <td>128.45</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 4: olist_order_reviews_dataset
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review_id</th>
      <th>order_id</th>
      <th>review_score</th>
      <th>review_comment_title</th>
      <th>review_comment_message</th>
      <th>review_creation_date</th>
      <th>review_answer_timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7bc2406110b926393aa56f80a40eba40</td>
      <td>73fc7af87114b39712e6da79b0a377eb</td>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-01-18 00:00:00</td>
      <td>2018-01-18 21:46:59</td>
    </tr>
    <tr>
      <th>1</th>
      <td>80e641a11e56f04c1ad469d5645fdfde</td>
      <td>a548910a1c6147796b98fdf73dbeba33</td>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-03-10 00:00:00</td>
      <td>2018-03-11 03:05:13</td>
    </tr>
    <tr>
      <th>2</th>
      <td>228ce5500dc1d8e020d8d1322874b6f0</td>
      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-02-17 00:00:00</td>
      <td>2018-02-18 14:36:24</td>
    </tr>
    <tr>
      <th>3</th>
      <td>e64fb393e7b32834bb789ff8bb30750e</td>
      <td>658677c97b385a9be170737859d3511b</td>
      <td>5</td>
      <td>NaN</td>
      <td>Recebi bem antes do prazo estipulado.</td>
      <td>2017-04-21 00:00:00</td>
      <td>2017-04-21 22:02:06</td>
    </tr>
    <tr>
      <th>4</th>
      <td>f7c4243c7fe1938f181bec41a392bdeb</td>
      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>
      <td>5</td>
      <td>NaN</td>
      <td>ParabÃ©ns lojas lannister adorei comprar pela I...</td>
      <td>2018-03-01 00:00:00</td>
      <td>2018-03-02 10:26:53</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 5: olist_orders_dataset
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>customer_id</th>
      <th>order_status</th>
      <th>order_purchase_timestamp</th>
      <th>order_approved_at</th>
      <th>order_delivered_carrier_date</th>
      <th>order_delivered_customer_date</th>
      <th>order_estimated_delivery_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>e481f51cbdc54678b7cc49136f2d6af7</td>
      <td>9ef432eb6251297304e76186b10a928d</td>
      <td>delivered</td>
      <td>2017-10-02 10:56:33</td>
      <td>2017-10-02 11:07:15</td>
      <td>2017-10-04 19:55:00</td>
      <td>2017-10-10 21:25:13</td>
      <td>2017-10-18 00:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>53cdb2fc8bc7dce0b6741e2150273451</td>
      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>
      <td>delivered</td>
      <td>2018-07-24 20:41:37</td>
      <td>2018-07-26 03:24:27</td>
      <td>2018-07-26 14:31:00</td>
      <td>2018-08-07 15:27:45</td>
      <td>2018-08-13 00:00:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>47770eb9100c2d0c44946d9cf07ec65d</td>
      <td>41ce2a54c0b03bf3443c3d931a367089</td>
      <td>delivered</td>
      <td>2018-08-08 08:38:49</td>
      <td>2018-08-08 08:55:23</td>
      <td>2018-08-08 13:50:00</td>
      <td>2018-08-17 18:06:29</td>
      <td>2018-09-04 00:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>
      <td>f88197465ea7920adcdbec7375364d82</td>
      <td>delivered</td>
      <td>2017-11-18 19:28:06</td>
      <td>2017-11-18 19:45:59</td>
      <td>2017-11-22 13:39:59</td>
      <td>2017-12-02 00:28:42</td>
      <td>2017-12-15 00:00:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>
      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>
      <td>delivered</td>
      <td>2018-02-13 21:18:39</td>
      <td>2018-02-13 22:20:29</td>
      <td>2018-02-14 19:46:34</td>
      <td>2018-02-16 18:17:02</td>
      <td>2018-02-26 00:00:00</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 6: olist_products_dataset
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_id</th>
      <th>product_category_name</th>
      <th>product_name_lenght</th>
      <th>product_description_lenght</th>
      <th>product_photos_qty</th>
      <th>product_weight_g</th>
      <th>product_length_cm</th>
      <th>product_height_cm</th>
      <th>product_width_cm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>
      <td>perfumaria</td>
      <td>40.0</td>
      <td>287.0</td>
      <td>1.0</td>
      <td>225.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>14.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>
      <td>artes</td>
      <td>44.0</td>
      <td>276.0</td>
      <td>1.0</td>
      <td>1000.0</td>
      <td>30.0</td>
      <td>18.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>96bd76ec8810374ed1b65e291975717f</td>
      <td>esporte_lazer</td>
      <td>46.0</td>
      <td>250.0</td>
      <td>1.0</td>
      <td>154.0</td>
      <td>18.0</td>
      <td>9.0</td>
      <td>15.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>cef67bcfe19066a932b7673e239eb23d</td>
      <td>bebes</td>
      <td>27.0</td>
      <td>261.0</td>
      <td>1.0</td>
      <td>371.0</td>
      <td>26.0</td>
      <td>4.0</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9dc1a7de274444849c219cff195d0b71</td>
      <td>utilidades_domesticas</td>
      <td>37.0</td>
      <td>402.0</td>
      <td>4.0</td>
      <td>625.0</td>
      <td>20.0</td>
      <td>17.0</td>
      <td>13.0</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 7: olist_sellers_dataset
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>seller_id</th>
      <th>seller_zip_code_prefix</th>
      <th>seller_city</th>
      <th>seller_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3442f8959a84dea7ee197c632cb2df15</td>
      <td>13023</td>
      <td>campinas</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>
      <td>13844</td>
      <td>mogi guacu</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>
      <td>20031</td>
      <td>rio de janeiro</td>
      <td>RJ</td>
    </tr>
    <tr>
      <th>3</th>
      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>
      <td>4195</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>
      <td>12914</td>
      <td>braganca paulista</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dfs 8: product_category_name_translation
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_category_name</th>
      <th>product_category_name_english</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>beleza_saude</td>
      <td>health_beauty</td>
    </tr>
    <tr>
      <th>1</th>
      <td>informatica_acessorios</td>
      <td>computers_accessories</td>
    </tr>
    <tr>
      <th>2</th>
      <td>automotivo</td>
      <td>auto</td>
    </tr>
    <tr>
      <th>3</th>
      <td>cama_mesa_banho</td>
      <td>bed_bath_table</td>
    </tr>
    <tr>
      <th>4</th>
      <td>moveis_decoracao</td>
      <td>furniture_decor</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="data-preparation">
<h2>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df11</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">dfs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;order_id&#39;</span><span class="p">)[[</span><span class="s1">&#39;product_id&#39;</span><span class="p">,</span><span class="s1">&#39;customer_id&#39;</span><span class="p">,</span><span class="s1">&#39;order_purchase_timestamp&#39;</span><span class="p">]]</span>
<span class="n">df12</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">dfs</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;product_category_name&#39;</span><span class="p">)[[</span><span class="s1">&#39;product_id&#39;</span><span class="p">,</span><span class="s1">&#39;product_category_name_english&#39;</span><span class="p">]]</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df11</span><span class="p">,</span> <span class="n">df12</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;product_id&#39;</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;sku&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;product_category_name_english&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">cumcount</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;str&#39;</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;product_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;product_category_name_english&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;sku&#39;</span><span class="p">]</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;implicit_interaction_weight&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;order_purchase_timestamp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;order_purchase_timestamp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">timestamp</span><span class="p">())</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[[</span><span class="s1">&#39;customer_id&#39;</span><span class="p">,</span> <span class="s1">&#39;product_id&#39;</span><span class="p">,</span> <span class="s1">&#39;implicit_interaction_weight&#39;</span><span class="p">,</span> <span class="s1">&#39;order_purchase_timestamp&#39;</span><span class="p">]]</span>
<span class="n">df1</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;USERID&#39;</span><span class="p">,</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">,</span><span class="s1">&#39;RATING&#39;</span><span class="p">,</span><span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">]</span>
<span class="n">df1</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>USERID</th>
      <th>ITEMID</th>
      <th>RATING</th>
      <th>TIMESTAMP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3ce436f183e68e07877b285a838db11a</td>
      <td>cool_stuff_0</td>
      <td>1</td>
      <td>1.505293e+09</td>
    </tr>
    <tr>
      <th>1</th>
      <td>f6dd3ec061db4e3987629fe6b26e5cce</td>
      <td>pet_shop_0</td>
      <td>1</td>
      <td>1.493204e+09</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6489ae5e4333f3693df5ad4372dab6d3</td>
      <td>furniture_decor_0</td>
      <td>1</td>
      <td>1.515940e+09</td>
    </tr>
    <tr>
      <th>3</th>
      <td>d4eb9395c8c0431ee92fce09860c5a06</td>
      <td>perfumery_0</td>
      <td>1</td>
      <td>1.533722e+09</td>
    </tr>
    <tr>
      <th>4</th>
      <td>58dbd0b2d70206bf40e62cd34e84d795</td>
      <td>garden_tools_0</td>
      <td>1</td>
      <td>1.486217e+09</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>112645</th>
      <td>b51593916b4b8e0d6f66f2ae24f2673d</td>
      <td>housewares_6963</td>
      <td>1</td>
      <td>1.524492e+09</td>
    </tr>
    <tr>
      <th>112646</th>
      <td>84c5d4fbaf120aae381fad077416eaa0</td>
      <td>computers_accessories_7825</td>
      <td>1</td>
      <td>1.531564e+09</td>
    </tr>
    <tr>
      <th>112647</th>
      <td>29309aa813182aaddc9b259e31b870e6</td>
      <td>sports_leisure_8640</td>
      <td>1</td>
      <td>1.508778e+09</td>
    </tr>
    <tr>
      <th>112648</th>
      <td>b5e6afd5a41800fdf401e0272ca74655</td>
      <td>computers_accessories_7826</td>
      <td>1</td>
      <td>1.502752e+09</td>
    </tr>
    <tr>
      <th>112649</th>
      <td>96d649da0cc4ff33bb408b199d4c7dcf</td>
      <td>bed_bath_table_11114</td>
      <td>1</td>
      <td>1.528564e+09</td>
    </tr>
  </tbody>
</table>
<p>111023 rows Ã— 4 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">interactions_dict</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;USERID&#39;</span><span class="p">,</span> <span class="s1">&#39;ITEMID&#39;</span><span class="p">])[</span><span class="s1">&#39;RATING&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">interactions_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">interactions_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">interactions_dict</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">interactions</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">interactions</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">{</span>
    <span class="s1">&#39;USERID&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;USERID&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;ITEMID&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;RATING&#39;</span> <span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;RATING&#39;</span><span class="p">]),</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;00012a2ce6f8dcda20d059ce98491703&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;toys_1531&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;000161a058600d5901f007fab4c27140&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;health_beauty_6074&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;0001fd6190edaaf884bcaf3d49edf079&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;baby_571&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;0002414f95344307404f0ace7a26f1d5&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;cool_stuff_1263&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;000379cdec625522490c315e70c7a9fb&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;bed_bath_table_483&#39;&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">items_dict</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
<span class="n">items_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">items_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">items</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">items_dict</span><span class="p">)</span>

<span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### get unique item and user id&#39;s as a lookup table</span>
<span class="n">unique_item_titles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">))))</span>
<span class="n">unique_user_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">interactions</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1_000</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">]))))</span>

<span class="c1"># Randomly shuffle data and split between train and test.</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">shuffled</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">reshuffle_each_iteration</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">shuffled</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">60_000</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">shuffled</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="mi">60_000</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">20_000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="retrieval-model">
<h2>Retrieval Model<a class="headerlink" href="#retrieval-model" title="Permalink to this headline">Â¶</a></h2>
<p>There are five important component of the query and candicate tower: candidate model (item_model), querty model (user_model), metrics, task, and compute loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RetailModel</span><span class="p">(</span><span class="n">tfrs</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_model</span><span class="p">,</span> <span class="n">item_model</span><span class="p">):</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
      
      <span class="c1">### Candidate model (item)</span>
      <span class="c1">### This is Keras preprocessing layers to first convert user ids to integers, </span>
      <span class="c1">### and then convert those to user embeddings via an Embedding layer. </span>
      <span class="c1">### We use the list of unique user ids we computed earlier as a vocabulary:</span>
      <span class="n">item_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                                      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                                      <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_titles</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                                      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_titles</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
                                      <span class="p">])</span>
      <span class="c1">### we pass the embedding layer into item model</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="n">item_model</span>
          
      <span class="c1">### Query model (users)    </span>
      <span class="n">user_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                                      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                                      <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                                      <span class="c1"># We add an additional embedding to account for unknown tokens.</span>
                                      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
                                      <span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">user_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="n">user_model</span>
      
      <span class="c1">### for retrieval model. we take top-k accuracy as metrics</span>
      <span class="n">metrics</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FactorizedTopK</span><span class="p">(</span><span class="n">candidates</span><span class="o">=</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">item_model</span><span class="p">))</span>
      
      <span class="c1"># define the task, which is retrieval</span>
      <span class="n">task</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Retrieval</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
      
      <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">task</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
      <span class="c1"># We pick out the user features and pass them into the user model.</span>
      <span class="n">user_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">])</span>
      <span class="c1"># And pick out the movie features and pass them into the movie model,</span>
      <span class="c1"># getting embeddings back.</span>
      <span class="n">positive_movie_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">])</span>

      <span class="c1"># The task computes the loss and the metrics.</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">(</span><span class="n">user_embeddings</span><span class="p">,</span> <span class="n">positive_movie_embeddings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### Fitting and evaluating</span>

<span class="c1">### we choose the dimensionality of the query and candicate representation.</span>
<span class="n">embedding_dimension</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1">## we pass the model, which is the same model we created in the query and candidate tower, into the model</span>
<span class="n">item_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                                <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_titles</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_titles</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
                                <span class="p">])</span>

<span class="n">user_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                                <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
                                <span class="c1"># We add an additional embedding to account for unknown tokens.</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
                                <span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RetailModel</span><span class="p">(</span><span class="n">user_model</span><span class="p">,</span> <span class="n">item_model</span><span class="p">)</span>

<span class="c1"># a smaller learning rate may make the model move slower and prone to overfitting, so we stick to 0.1</span>
<span class="c1"># other optimizers, such as SGD and Adam, are listed here https://www.tensorflow.org/api_docs/python/tf/keras/optimizers</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">cached_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">8192</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">cached_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="c1">## fit the model with ten epochs</span>
<span class="n">model_hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1">#evaluate the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.
8/8 [==============================] - 400s 49s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_50_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.6667e-04 - loss: 62067.0734 - regularization_loss: 0.0000e+00 - total_loss: 62067.0734
Epoch 2/10
8/8 [==============================] - 396s 49s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0935 - factorized_top_k/top_10_categorical_accuracy: 0.1493 - factorized_top_k/top_50_categorical_accuracy: 0.3334 - factorized_top_k/top_100_categorical_accuracy: 0.4331 - loss: 61949.0182 - regularization_loss: 0.0000e+00 - total_loss: 61949.0182
Epoch 3/10
8/8 [==============================] - 392s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5566 - factorized_top_k/top_10_categorical_accuracy: 0.7027 - factorized_top_k/top_50_categorical_accuracy: 0.9107 - factorized_top_k/top_100_categorical_accuracy: 0.9537 - loss: 61799.8203 - regularization_loss: 0.0000e+00 - total_loss: 61799.8203
Epoch 4/10
8/8 [==============================] - 391s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6852 - factorized_top_k/top_10_categorical_accuracy: 0.8421 - factorized_top_k/top_50_categorical_accuracy: 0.9835 - factorized_top_k/top_100_categorical_accuracy: 0.9948 - loss: 61557.9358 - regularization_loss: 0.0000e+00 - total_loss: 61557.9358
Epoch 5/10
8/8 [==============================] - 390s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6006 - factorized_top_k/top_10_categorical_accuracy: 0.7915 - factorized_top_k/top_50_categorical_accuracy: 0.9886 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 61139.4262 - regularization_loss: 0.0000e+00 - total_loss: 61139.4262
Epoch 6/10
8/8 [==============================] - 389s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5041 - factorized_top_k/top_10_categorical_accuracy: 0.7085 - factorized_top_k/top_50_categorical_accuracy: 0.9848 - factorized_top_k/top_100_categorical_accuracy: 0.9976 - loss: 60430.4431 - regularization_loss: 0.0000e+00 - total_loss: 60430.4431
Epoch 7/10
8/8 [==============================] - 390s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.4606 - factorized_top_k/top_10_categorical_accuracy: 0.6669 - factorized_top_k/top_50_categorical_accuracy: 0.9832 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 59296.1063 - regularization_loss: 0.0000e+00 - total_loss: 59296.1063
Epoch 8/10
8/8 [==============================] - 384s 47s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.4800 - factorized_top_k/top_10_categorical_accuracy: 0.6913 - factorized_top_k/top_50_categorical_accuracy: 0.9875 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - loss: 57606.5898 - regularization_loss: 0.0000e+00 - total_loss: 57606.5898
Epoch 9/10
8/8 [==============================] - 387s 48s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5498 - factorized_top_k/top_10_categorical_accuracy: 0.7657 - factorized_top_k/top_50_categorical_accuracy: 0.9935 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 55261.9683 - regularization_loss: 0.0000e+00 - total_loss: 55261.9683
Epoch 10/10
8/8 [==============================] - 385s 47s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6651 - factorized_top_k/top_10_categorical_accuracy: 0.8625 - factorized_top_k/top_50_categorical_accuracy: 0.9977 - factorized_top_k/top_100_categorical_accuracy: 0.9997 - loss: 52214.9371 - regularization_loss: 0.0000e+00 - total_loss: 52214.9371
5/5 [==============================] - 132s 26s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.4167 - regularization_loss: 0.0000e+00 - total_loss: 32588.4167
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;factorized_top_k/top_100_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_10_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_1_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_50_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_5_categorical_accuracy&#39;: 0.0,
 &#39;loss&#39;: 29625.80078125,
 &#39;regularization_loss&#39;: 0,
 &#39;total_loss&#39;: 29625.80078125}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5/5 [==============================] - 130s 26s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.4167 - regularization_loss: 0.0000e+00 - total_loss: 32588.4167
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;factorized_top_k/top_100_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_10_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_1_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_50_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_5_categorical_accuracy&#39;: 0.0,
 &#39;loss&#39;: 29625.80078125,
 &#39;regularization_loss&#39;: 0,
 &#39;total_loss&#39;: 29625.80078125}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># num_validation_runs = len(one_layer_history.history[&quot;val_factorized_top_k/top_100_categorical_accuracy&quot;])</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model_hist</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;factorized_top_k/top_100_categorical_accuracy&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Accuracy vs epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Top-100 accuracy&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7f289dc49790&gt;
</pre></div>
</div>
<img alt="_images/T368830_Multi_Task_Recommender_on_Olist_dataset_using_TFRS_Library_24_1.png" src="_images/T368830_Multi_Task_Recommender_on_Olist_dataset_using_TFRS_Library_24_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a model that takes in raw query features, and</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">factorized_top_k</span><span class="o">.</span><span class="n">BruteForce</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">user_model</span><span class="p">)</span>
<span class="c1"># recommends items out of the entire dataset.</span>
<span class="n">index</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">item_model</span><span class="p">),</span> <span class="n">items</span><span class="p">)</span>

<span class="c1"># Get recommendations.</span>
<span class="n">j</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">items</span> <span class="o">=</span> <span class="n">index</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">j</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recommendations for user %s: </span><span class="si">{</span><span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">j</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Recommendations for user 40: [b&#39;housewares_1189&#39; b&#39;housewares_1181&#39; b&#39;housewares_1186&#39;
 b&#39;housewares_1188&#39; b&#39;electronics_1206&#39; b&#39;housewares_1185&#39;
 b&#39;housewares_1190&#39; b&#39;electronics_1205&#39; b&#39;housewares_1182&#39;
 b&#39;housewares_1184&#39;]
</pre></div>
</div>
</div>
</div>
<p>There you are, our first simple yet effective recommendation engine using retrieval task. But what about ranking? can we rank all the items for best to worst, only then run retrieval task to retrieve selected items from the short list? Now we can explore another type of recommendation task: ranking.</p>
</div>
<div class="section" id="ranking-model">
<h2>Ranking Model<a class="headerlink" href="#ranking-model" title="Permalink to this headline">Â¶</a></h2>
<p>Ranking model is able to assist retrieval by ranking all the items from highest to lowest, predcting a probablity that a user may or may not like it. Ranking model is useful to filter out items that are not relevant for the user before retrieval task, making retrieval task much more accurate and efficient.</p>
<p>Here, many embedding layers works similarly with retrieval model, with addition of multiple hidden layers under Sequential latyers, where we can stack multiple dense layers. We split the query and candidate tower separately, and call them later into the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RankingModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">embedding_dimension</span> <span class="o">=</span> <span class="mi">32</span>

        <span class="c1"># Compute embeddings for users.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># Compute embeddings for movies.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_titles</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_titles</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># Compute predictions.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="c1"># Learn multiple dense layers.</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
          <span class="c1"># Make rating predictions in the final layer.</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">])</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>

        <span class="n">user_id</span><span class="p">,</span> <span class="n">item_id</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="n">user_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_embeddings</span><span class="p">(</span><span class="n">user_id</span><span class="p">)</span>
        <span class="n">item_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embeddings</span><span class="p">(</span><span class="n">item_id</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratings</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">user_embedding</span><span class="p">,</span> <span class="n">item_embedding</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>This model takes user ids and item ids, and outputs a predicted rating, for example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">RankingModel</span><span class="p">()(([</span><span class="s2">&quot;f6dd3ec061db4e3987629fe6b26e5cce&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;pet_shop_0&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;list&#39;&gt; input: [&#39;f6dd3ec061db4e3987629fe6b26e5cce&#39;]
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;list&#39;&gt; input: [&#39;pet_shop_0&#39;]
Consider rewriting this model with the Functional API.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01409375]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RetailModel</span><span class="p">(</span><span class="n">tfrs</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ranking_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="n">RankingModel</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Ranking</span><span class="p">(</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
          <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">RootMeanSquaredError</span><span class="p">()]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">rating_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranking_model</span><span class="p">(</span>
            <span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">],</span> <span class="n">features</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">]))</span>

        <span class="c1"># The task computes the loss and the metrics.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;RATING&quot;</span><span class="p">],</span> <span class="n">predictions</span><span class="o">=</span><span class="n">rating_predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RetailModel</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>

<span class="n">cached_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">8192</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">cached_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/100
8/8 [==============================] - 3s 31ms/step - root_mean_squared_error: 0.9951 - loss: 0.8617 - regularization_loss: 0.0000e+00 - total_loss: 0.8617
Epoch 2/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.2813 - loss: 0.0668 - regularization_loss: 0.0000e+00 - total_loss: 0.0668
Epoch 3/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 0.0593 - loss: 0.0030 - regularization_loss: 0.0000e+00 - total_loss: 0.0030
Epoch 4/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.0126 - loss: 1.3481e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.3481e-04
Epoch 5/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.0027 - loss: 6.1202e-06 - regularization_loss: 0.0000e+00 - total_loss: 6.1202e-06
Epoch 6/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 5.7347e-04 - loss: 2.7786e-07 - regularization_loss: 0.0000e+00 - total_loss: 2.7786e-07
Epoch 7/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.2221e-04 - loss: 1.2619e-08 - regularization_loss: 0.0000e+00 - total_loss: 1.2619e-08
Epoch 8/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 2.6041e-05 - loss: 5.7305e-10 - regularization_loss: 0.0000e+00 - total_loss: 5.7305e-10
Epoch 9/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 5.5814e-06 - loss: 2.6307e-11 - regularization_loss: 0.0000e+00 - total_loss: 2.6307e-11
Epoch 10/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1712e-06 - loss: 1.1586e-12 - regularization_loss: 0.0000e+00 - total_loss: 1.1586e-12
Epoch 11/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 2.6456e-07 - loss: 5.9607e-14 - regularization_loss: 0.0000e+00 - total_loss: 5.9607e-14
Epoch 12/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 13/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 14/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 15/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 16/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 17/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 18/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 19/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 20/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 21/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 22/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 23/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 24/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 25/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 26/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 27/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 28/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 29/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 30/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 31/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 32/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 33/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 34/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 35/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 36/100
8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 37/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 38/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 39/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 40/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 41/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 42/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 43/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 44/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 45/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 46/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 47/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 48/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 49/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 50/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 51/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 52/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 53/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 54/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 55/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 56/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 57/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 58/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 59/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 60/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 61/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 62/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 63/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 64/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 65/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 66/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 67/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 68/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 69/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 70/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 71/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 72/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 73/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 74/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 75/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 76/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 77/100
8/8 [==============================] - 0s 13ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 78/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 79/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 80/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 81/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 82/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 83/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 84/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 85/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 86/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 87/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 88/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 89/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 90/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 91/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 92/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 93/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 94/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 95/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 96/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 97/100
8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 98/100
8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 99/100
8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
Epoch 100/100
8/8 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7f28a37c5d90&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5/5 [==============================] - 2s 22ms/step - root_mean_squared_error: 1.1921e-07 - loss: 1.4211e-14 - regularization_loss: 0.0000e+00 - total_loss: 1.4211e-14
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;loss&#39;: 1.4210854715202004e-14,
 &#39;regularization_loss&#39;: 0,
 &#39;root_mean_squared_error&#39;: 1.1920928955078125e-07,
 &#39;total_loss&#39;: 1.4210854715202004e-14}
</pre></div>
</div>
</div>
</div>
<p>The RMSE is not very good, which we shall see how we can improve it by adding more features and combining ranking and retrieval model together.</p>
</div>
<div class="section" id="adding-context">
<h2>Adding Context<a class="headerlink" href="#adding-context" title="Permalink to this headline">Â¶</a></h2>
<p>Adding Timestamp and Text embeddings</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">interactions_dict</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;USERID&#39;</span><span class="p">,</span> <span class="s1">&#39;ITEMID&#39;</span><span class="p">,</span> <span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">])[</span><span class="s1">&#39;RATING&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">interactions_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">interactions_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">interactions_dict</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">interactions</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">interactions</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">{</span>
    <span class="s1">&#39;USERID&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;USERID&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;ITEMID&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">],</span> 
    <span class="s1">&#39;RATING&#39;</span> <span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;RATING&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;TIMESTAMP&#39;</span> <span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">],</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;00012a2ce6f8dcda20d059ce98491703&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;toys_1531&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1510675706.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;000161a058600d5901f007fab4c27140&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;health_beauty_6074&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1500198032.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;0001fd6190edaaf884bcaf3d49edf079&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;baby_571&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1488280003.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;0002414f95344307404f0ace7a26f1d5&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;cool_stuff_1263&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1502888960.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
{&#39;USERID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;000379cdec625522490c315e70c7a9fb&#39;&gt;, &#39;ITEMID&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;bed_bath_table_483&#39;&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor: shape=(), dtype=float64, numpy=1522676537.0&gt;, &#39;RATING&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">items_dict</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
<span class="n">items_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">items_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">items</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">items_dict</span><span class="p">)</span>

<span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;ITEMID&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>timestamp is an exmaple of continuous features, which needs to be rescaled, or otherwise it will be too large for the model. there are other methods to reduce the size of the timestamp, ,such as standardization and normalization here we use discretization, which puts them into buckets of categorical features,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">timestamps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">interactions</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)))</span>
<span class="n">max_timestamp</span> <span class="o">=</span> <span class="n">timestamps</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">min_timestamp</span> <span class="o">=</span> <span class="n">timestamps</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">timestamp_buckets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
    <span class="n">min_timestamp</span><span class="p">,</span> <span class="n">max_timestamp</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">,)</span>

<span class="n">item_ids</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10_000</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">])</span>
<span class="n">user_ids</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10_000</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">])</span>

<span class="n">unique_item_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">item_ids</span><span class="p">)))</span>
<span class="n">unique_user_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">user_ids</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">shuffled</span> <span class="o">=</span> <span class="n">interactions</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">reshuffle_each_iteration</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">shuffled</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">60_000</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">shuffled</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="mi">60_000</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">20_000</span><span class="p">)</span>

<span class="n">cached_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span>
<span class="n">cached_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We split the query and candidate model separately to allow more stacked embedding layers before we pass it into the model. In the user model (query model), in addition to user embedding, we also add timestamp embedding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### user model</span>

<span class="k">class</span> <span class="nc">UserModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_timestamps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_use_timestamps</span> <span class="o">=</span> <span class="n">use_timestamps</span>

        <span class="c1">## embed user id from unique_user_ids</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
                <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
        <span class="p">])</span>

        <span class="c1">## embed timestamp</span>
        <span class="k">if</span> <span class="n">use_timestamps</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">timestamp_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">Discretization</span><span class="p">(</span><span class="n">timestamp_buckets</span><span class="o">.</span><span class="n">tolist</span><span class="p">()),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">timestamp_buckets</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">normalized_timestamp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">Normalization</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">normalized_timestamp</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">timestamps</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_timestamps</span><span class="p">:</span>
              <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">])</span>

        <span class="c1">## all features here</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">user_embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">]),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">timestamp_embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">]),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">normalized_timestamp</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">]),</span>
        <span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For the candidate model, we want the model to learn from the text features too by processing the text features that is able to learn words that are similar to each other. It can also identify OOV (out of Vocabulary) word, so if we are predicing a new item, the model can calculate them appropriately.</p>
<p>Below, the item name will be transformated by tokenization (splitting into constituent words or word-pieces), followed by vocabulary learning, then followed by an embedding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### candidate model</span>

<span class="k">class</span> <span class="nc">ItemModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">10_000</span>

        <span class="c1">## embed title from unique_item_ids</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">title_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
              <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1">## processing text features: item title vectorizer (see self.title_vectorizer)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">title_vectorizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">TextVectorization</span><span class="p">(</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">)</span>

        <span class="c1">## we apply title vectorizer to items</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">title_text_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">title_vectorizer</span><span class="p">,</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_tokens</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">(),</span>
        <span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">title_vectorizer</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">titles</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">title_embedding</span><span class="p">(</span><span class="n">titles</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">title_text_embedding</span><span class="p">(</span><span class="n">titles</span><span class="p">),</span>
        <span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>With both UserModel and ItemModel defined, we can put together a combined model and implement our loss and metrics logic.</p>
<p>Note that we also need to make sure that the query model and candidate model output embeddings of compatible size. Because weâ€™ll be varying their sizes by adding more features, the easiest way to accomplish this is to use a dense projection layer after each model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RetailModel</span><span class="p">(</span><span class="n">tfrs</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_timestamps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1">## query model is user model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">UserModel</span><span class="p">(</span><span class="n">use_timestamps</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
        <span class="p">])</span>
        
        <span class="c1">## candidate model is the item model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">candidate_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">ItemModel</span><span class="p">(),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
        <span class="p">])</span>
        
        <span class="c1">## retrieval task, choose metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Retrieval</span><span class="p">(</span>
            <span class="n">metrics</span><span class="o">=</span><span class="n">tfrs</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FactorizedTopK</span><span class="p">(</span>
                <span class="n">candidates</span><span class="o">=</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">candidate_model</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># We only pass the user id and timestamp features into the query model. This</span>
        <span class="c1"># is to ensure that the training inputs would have the same keys as the</span>
        <span class="c1"># query inputs. Otherwise the discrepancy in input structure would cause an</span>
        <span class="c1"># error when loading the query model after saving it.</span>
        
        <span class="n">query_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_model</span><span class="p">({</span>
            <span class="s2">&quot;USERID&quot;</span><span class="p">:</span> <span class="n">features</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">],</span>
            <span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">:</span> <span class="n">features</span><span class="p">[</span><span class="s2">&quot;TIMESTAMP&quot;</span><span class="p">],</span>
        <span class="p">})</span>
        
        <span class="n">item_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">(</span><span class="n">query_embeddings</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Note: Baseline is with no timestamp feature.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RetailModel</span><span class="p">(</span><span class="n">use_timestamps</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/3
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
30/30 [==============================] - 422s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0564 - factorized_top_k/top_5_categorical_accuracy: 0.0614 - factorized_top_k/top_10_categorical_accuracy: 0.0640 - factorized_top_k/top_50_categorical_accuracy: 0.0715 - factorized_top_k/top_100_categorical_accuracy: 0.0752 - loss: 14855.2315 - regularization_loss: 0.0000e+00 - total_loss: 14855.2315
Epoch 2/3
30/30 [==============================] - 420s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0479 - factorized_top_k/top_5_categorical_accuracy: 0.0490 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.0508 - factorized_top_k/top_100_categorical_accuracy: 0.0516 - loss: 14047.4312 - regularization_loss: 0.0000e+00 - total_loss: 14047.4312
Epoch 3/3
30/30 [==============================] - 422s 14s/step - factorized_top_k/top_1_categorical_accuracy: 5.1667e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0026 - factorized_top_k/top_50_categorical_accuracy: 0.0101 - factorized_top_k/top_100_categorical_accuracy: 0.0195 - loss: 11625.8452 - regularization_loss: 0.0000e+00 - total_loss: 11625.8452
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7f2837bac9d0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
5/5 [==============================] - 137s 27s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33116.2435 - regularization_loss: 0.0000e+00 - total_loss: 33116.2435
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;factorized_top_k/top_100_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_10_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_1_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_50_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_5_categorical_accuracy&#39;: 0.0,
 &#39;loss&#39;: 30138.40234375,
 &#39;regularization_loss&#39;: 0,
 &#39;total_loss&#39;: 30138.40234375}
</pre></div>
</div>
</div>
</div>
<p>Including time into the model:</p>
<p>Do the result change if we add time features?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span><span class="n">x</span> <span class="n">RetailModel</span><span class="p">(</span><span class="n">use_timestamps</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/3
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize
WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize
30/30 [==============================] - 430s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0077 - factorized_top_k/top_5_categorical_accuracy: 0.0166 - factorized_top_k/top_10_categorical_accuracy: 0.0228 - factorized_top_k/top_50_categorical_accuracy: 0.0459 - factorized_top_k/top_100_categorical_accuracy: 0.0664 - loss: 14859.7737 - regularization_loss: 0.0000e+00 - total_loss: 14859.7737
Epoch 2/3
30/30 [==============================] - 430s 14s/step - factorized_top_k/top_1_categorical_accuracy: 2.1667e-04 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0011 - factorized_top_k/top_50_categorical_accuracy: 0.0032 - factorized_top_k/top_100_categorical_accuracy: 0.0051 - loss: 12473.8825 - regularization_loss: 0.0000e+00 - total_loss: 12473.8825
Epoch 3/3
30/30 [==============================] - 432s 14s/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0070 - factorized_top_k/top_10_categorical_accuracy: 0.0132 - factorized_top_k/top_50_categorical_accuracy: 0.0543 - factorized_top_k/top_100_categorical_accuracy: 0.1117 - loss: 8039.4111 - regularization_loss: 0.0000e+00 - total_loss: 8039.4111
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7f27e41ea250&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;USERID&#39;: &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None,) dtype=string&gt;, &#39;TIMESTAMP&#39;: &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None,) dtype=float64&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize
5/5 [==============================] - 138s 27s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33796.7786 - regularization_loss: 0.0000e+00 - total_loss: 33796.7786
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;factorized_top_k/top_100_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_10_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_1_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_50_categorical_accuracy&#39;: 0.0,
 &#39;factorized_top_k/top_5_categorical_accuracy&#39;: 0.0,
 &#39;loss&#39;: 30721.021484375,
 &#39;regularization_loss&#39;: 0,
 &#39;total_loss&#39;: 30721.021484375}
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Note: Eventhough we only run it at three epochs, we can see accuracy increase as we add time into the model.</p>
</div></blockquote>
</div>
<div class="section" id="multi-task-model-with-relu-based-dnn">
<h2>Multi-Task Model with ReLU-based DNN<a class="headerlink" href="#multi-task-model-with-relu-based-dnn" title="Permalink to this headline">Â¶</a></h2>
<p>The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">tfrs</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">rating_weight</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">retrieval_weight</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We take the loss weights in the constructor: this allows us to instantiate</span>
        <span class="c1"># several model objects with different loss weights.</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">embedding_dimension</span> <span class="o">=</span> <span class="mi">32</span>

        <span class="c1"># item models.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_item_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_item_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
        <span class="p">])</span>
            
        <span class="c1">## user model    </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StringLookup</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="n">unique_user_ids</span><span class="p">,</span> <span class="n">mask_token</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_user_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_dimension</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># A small model to take in user and item embeddings and predict ratings.</span>
        <span class="c1"># We can make this as complicated as we want as long as we output a scalar</span>
        <span class="c1"># as our prediction.</span>
        
        <span class="c1">## this is Relu-Based DNN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rating_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">])</span>

        <span class="c1"># rating and retrieval task.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rating_task</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Ranking</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">RootMeanSquaredError</span><span class="p">()],</span>
        <span class="p">)</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">retrieval_task</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span> <span class="o">=</span> <span class="n">tfrs</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">Retrieval</span><span class="p">(</span>
            <span class="n">metrics</span><span class="o">=</span><span class="n">tfrs</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FactorizedTopK</span><span class="p">(</span>
                <span class="n">candidates</span><span class="o">=</span><span class="n">items</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># The loss weights.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rating_weight</span> <span class="o">=</span> <span class="n">rating_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">retrieval_weight</span> <span class="o">=</span> <span class="n">retrieval_weight</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># We pick out the user features and pass them into the user model.</span>
        <span class="n">user_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;USERID&quot;</span><span class="p">])</span>
        
        <span class="c1"># And pick out the item features and pass them into the item model.</span>
        <span class="n">item_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_model</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;ITEMID&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">user_embeddings</span><span class="p">,</span>
            <span class="n">item_embeddings</span><span class="p">,</span>
            <span class="c1"># We apply the multi-layered rating model to a concatentation of</span>
            <span class="c1"># user and item embeddings.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rating_model</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">user_embeddings</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>

        <span class="c1">## ratings go here as a method to compute loss</span>
        <span class="n">ratings</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;RATING&quot;</span><span class="p">)</span>

        <span class="n">user_embeddings</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">,</span> <span class="n">rating_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># We compute the loss for each task.</span>
        <span class="n">rating_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rating_task</span><span class="p">(</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">ratings</span><span class="p">,</span>
            <span class="n">predictions</span><span class="o">=</span><span class="n">rating_predictions</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">retrieval_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">retrieval_task</span><span class="p">(</span><span class="n">user_embeddings</span><span class="p">,</span> <span class="n">item_embeddings</span><span class="p">)</span>

        <span class="c1"># And combine them using the loss weights.</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rating_weight</span> <span class="o">*</span> <span class="n">rating_loss</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">retrieval_weight</span> <span class="o">*</span> <span class="n">retrieval_loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="rating-specialized-model">
<h3>Rating-specialized model<a class="headerlink" href="#rating-specialized-model" title="Permalink to this headline">Â¶</a></h3>
<p>Depending on the weights we assign, the model will encode a different balance of the tasks. Letâ€™s start with a model that only considers ratings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">rating_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">retrieval_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">cached_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">8192</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">cached_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retrieval top-100 accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;factorized_top_k/top_100_categorical_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ranking RMSE: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;root_mean_squared_error&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/3
8/8 [==============================] - 388s 48s/step - root_mean_squared_error: 0.4401 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 7.8333e-04 - loss: 0.1581 - regularization_loss: 0.0000e+00 - total_loss: 0.1581
Epoch 2/3
8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.0205 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 1.1667e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.0000e-04 - loss: 3.7047e-04 - regularization_loss: 0.0000e+00 - total_loss: 3.7047e-04
Epoch 3/3
8/8 [==============================] - 386s 48s/step - root_mean_squared_error: 0.0125 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_10_categorical_accuracy: 1.1667e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.0000e-04 - loss: 1.5387e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5387e-04
5/5 [==============================] - 133s 26s/step - root_mean_squared_error: 0.0123 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 9.0000e-04 - loss: 1.5055e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5055e-04
Retrieval top-100 accuracy: 0.001.
Ranking RMSE: 0.012.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="retrieval-specialized-model">
<h3>Retrieval-specialized model<a class="headerlink" href="#retrieval-specialized-model" title="Permalink to this headline">Â¶</a></h3>
<p>Letâ€™s now try a model that focuses on retrieval only.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">rating_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">retrieval_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retrieval top-100 accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;factorized_top_k/top_100_categorical_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ranking RMSE: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;root_mean_squared_error&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/3
8/8 [==============================] - 382s 47s/step - root_mean_squared_error: 0.9892 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_10_categorical_accuracy: 6.6667e-05 - factorized_top_k/top_50_categorical_accuracy: 3.8333e-04 - factorized_top_k/top_100_categorical_accuracy: 7.0000e-04 - loss: 62067.1797 - regularization_loss: 0.0000e+00 - total_loss: 62067.1797
Epoch 2/3
8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.9881 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0918 - factorized_top_k/top_10_categorical_accuracy: 0.1484 - factorized_top_k/top_50_categorical_accuracy: 0.3325 - factorized_top_k/top_100_categorical_accuracy: 0.4333 - loss: 61949.0569 - regularization_loss: 0.0000e+00 - total_loss: 61949.0569
Epoch 3/3
8/8 [==============================] - 385s 47s/step - root_mean_squared_error: 0.9851 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.5590 - factorized_top_k/top_10_categorical_accuracy: 0.7058 - factorized_top_k/top_50_categorical_accuracy: 0.9094 - factorized_top_k/top_100_categorical_accuracy: 0.9534 - loss: 61799.7860 - regularization_loss: 0.0000e+00 - total_loss: 61799.7860
5/5 [==============================] - 130s 26s/step - root_mean_squared_error: 0.9883 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 32588.8281 - regularization_loss: 0.0000e+00 - total_loss: 32588.8281
Retrieval top-100 accuracy: 0.000.
Ranking RMSE: 0.988.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="joint-model">
<h3>Joint model<a class="headerlink" href="#joint-model" title="Permalink to this headline">Â¶</a></h3>
<p>Letâ€™s now train a model that assigns positive weights to both tasks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">rating_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">retrieval_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cached_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">cached_test</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retrieval top-100 accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;factorized_top_k/top_100_categorical_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ranking RMSE: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;root_mean_squared_error&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/3
8/8 [==============================] - 383s 47s/step - root_mean_squared_error: 0.4693 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.6667e-05 - factorized_top_k/top_10_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_50_categorical_accuracy: 2.6667e-04 - factorized_top_k/top_100_categorical_accuracy: 7.5000e-04 - loss: 31033.7246 - regularization_loss: 0.0000e+00 - total_loss: 31033.7246
Epoch 2/3
8/8 [==============================] - 387s 48s/step - root_mean_squared_error: 0.0133 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0084 - factorized_top_k/top_10_categorical_accuracy: 0.0152 - factorized_top_k/top_50_categorical_accuracy: 0.0466 - factorized_top_k/top_100_categorical_accuracy: 0.0706 - loss: 31004.2229 - regularization_loss: 0.0000e+00 - total_loss: 31004.2229
Epoch 3/3
8/8 [==============================] - 382s 47s/step - root_mean_squared_error: 0.0138 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.1620 - factorized_top_k/top_10_categorical_accuracy: 0.2301 - factorized_top_k/top_50_categorical_accuracy: 0.4188 - factorized_top_k/top_100_categorical_accuracy: 0.5109 - loss: 30972.8370 - regularization_loss: 0.0000e+00 - total_loss: 30972.8370
5/5 [==============================] - 131s 26s/step - root_mean_squared_error: 0.0136 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_100_categorical_accuracy: 1.5000e-04 - loss: 16294.1732 - regularization_loss: 0.0000e+00 - total_loss: 16294.1732
Retrieval top-100 accuracy: 0.000.
Ranking RMSE: 0.014.
</pre></div>
</div>
</div>
</div>
<p>We can see that accuracy is highest and RMSE is lowest when we combine both ranking and retrieval together.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "sparsh-ai/multiobjective-optimizations",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="T559084_Multi_task_Learning_on_ML_100k_in_TFRS.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Multi-task Learning on ML-100k in TFRS</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="T671443_MAMO_Framework.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">MAMO Framework</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>