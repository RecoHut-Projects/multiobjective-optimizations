{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L553498 | MOO in Recommender Systems","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP2PqUVutD24C8FZ3ip7ANz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"I4SaMzFl2prK"},"source":["# MOO in Recommender Systems"]},{"cell_type":"markdown","metadata":{"id":"ip3WkybL2v78"},"source":["Recommender systems have been widely applied to several domains and applications. Traditional recommender systems usually deal with a single objective, such as minimizing the prediction errors or maximizing the ranking of the recommendation list. There is an emerging demand for multi-objective optimization so that the development of recommendation models can take multiple objectives into consideration, especially in the area of multi-stakeholder and multi-task recommender systems.\n","\n","Using MOO in recommender systems is not a novel practice. The earliest application of MOO in recommender systems may track back to the ones which balance different evaluation metrics (e.g., accuracy, diversity, novelty, etc.). Recently, there is an emerging demand in MOO, especially in some special type of recommender systems. Take the multi-task recommender system for example, researchers may utilize a joint learning to optimize multiple tasks in a model with shared representations (e.g., latent factors, feature embeddings, etc.).\n","\n","In many applications, there are multiple rich sources of feedback to draw upon. For example, an e-commerce site may record user visits to product pages (abundant, but relatively low signal), image clicks, adding to cart, and, finally, purchases. It may even record post-purchase signals such as reviews and returns. Integrating all these different forms of feedback is critical to building systems that users love to use, and that do not optimize for any one metric at the expense of overall performance. In addition, building a joint model for multiple tasks may produce better results than building a number of task-specific models. This is especially true where some data is abundant (for example, clicks), and some data is sparse (purchases, returns, manual reviews). In those scenarios, a joint model may be able to use representations learned from the abundant task to improve its predictions on the sparse task via a phenomenon known as [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning). For example, [this paper](https://openreview.net/pdf?id=SJxPVcSonN) shows that a model predicting explicit user ratings from sparse user surveys can be substantially improved by adding an auxiliary task that uses abundant click log data. Recommendation with multiple objectives is an important but difficult problem, where the coherent difficulty lies in the possible conflicts between objectives. In this case, multi-objective optimization is expected to be **Pareto efficient**, where no single objective can be further improved without hurting the others.\n","\n","MOO address the challenges of producing recommendations in multiobjective and multi-stakeholder (e.g. marketplaces) settings, including but not limited to the following topics:\n","\n","- Recommender systems with multiple objectives\n","- Value-aware recommendation (profit, value, purpose, etc.)\n","- Trade-off between relevance and bias in recommender systems\n","- Recommendation with multiple stakeholders\n","- Food recommendation with different objectives\n","- Group recommender systems\n","- Conflict handling in multi-stakeholder recommendation\n","- Fairness-aware recommender systems\n","- Balancing the long-term impacts of the recommendations and the users’ short term preferences\n","- News recommendation with editorial values\n","- Educational recommender systems with multiple, potentially conflicting, objectives\n","- Personalized medicine with the different objectives coming from the patients and physicians\n","\n","## Categories of Multi-Objective Recommendations\n","\n","### 1. Recommender Systems Balancing Multiple Metrics\n","\n","In traditional recommender systems, the goal is to generate a list of items that most likely meets the user’s need. There are many different metrics to evaluate user’s need. Here are three most used metrics during the offline evaluations:\n","\n","- Accuracy: measure the difference between recommended items and the expected items.\n","- Diversity: measurement of un-similarity between recommended items. Maintaining a certain level of diversity increase the chance for user to choose useful items from the list.\n","- Novelty: measure the likelihood that a recommender system to generate recommendations that user may not be aware of.\n","\n","When a recommender system tries to maximize all three metrics at the same time, it become a multi objective optimization problem. Each metric is an objective. In this case, increasing accuracy may reduce the diversity and novelty, since more items that user assessed in the testing data set are in recommendation list. Increasing diversity or novelty may also reduce the accuracy for the same reason.\n","\n","<p><center><figure><img src='_images/L553498_1.png'><figcaption>A 3-dimensional objective space. Points are possible hybrids and are represented by the corresponding level of accuracy, novelty and diversity. Hybrids lying in the Pareto frontier are not dominated by any other hybrid.</figcaption></figure></center></p>\n","\n","We have a recommendation system that tries to optimize multiple objectives that conflict each other. Another interesting benefit of applying MOO in this case is the fact that recommendations (movies, music, news) might soon become boring to the users if we focus just on accuracy. Diversity enable the recommender to recommend something different. Similarly, novelty enable it to recommend something never experienced before.\n","\n","### 2. Group Recommender Systems\n","\n","In contrast to traditional recommender systems, the group recommender systems [37] produce a list of recommended items to a group of users, e.g., group dining or travelling. The major challenge in group recommendations is to balance the individual and group satisfactions, since a member’s taste in the group may conflict with another member’s preferences in the same group. As a result, MOO can be applied to find a balance and improve group recommendations.\n","\n","In [this](https://dl.acm.org/doi/10.1145/3109859.3109887) paper, authors utilized the weighted sum as the scalarization method to combine two objectives – individual satisfaction and group fairness. They proposed to use greedy search and integer programming as the single objective optimizer. Their experiments were able to demonstrate that they could improve group recommendations by considering group fairness in the MOO process.\n","\n","### 3. Multi-Stakeholder Recommender Systems\n","\n","In **multi-stakeholder recommender systems**, the utilities of all stakeholders (end users, item sellers and platform owners) need to be maximized at same time. The challenge here is that increasing utility of one stakeholder may reduce the utilities of other stakeholders. For example, if the recommendation includes more expensive items, the seller’s utilities (profit) may increase at the cost of user’s utilities (items likely to buy). In conclusion, a multi-stakeholder recommender must deal with multi objectives that conflicts each other.\n","\n","The definition of the objectives in this category may vary from applications to applications. In the marketplace, buyers, sellers and the platform may be the stakeholders. In job seeking, the recruiter and the job seekers may be the stakeholders. Therefore, the definition of the stakeholders and the associated objectives are dependent with the specific applications or domains.\n","\n","Lin, et al. utilized scalarization to optimize the click through rate (CTR) and gross merchandise volume (GMV) in an e-commerce application. They defined the loss function based on CTR and GMV, and used the weighted sum to combine these two losses into a joint loss function. They tried different weights to perform the joint learning process and finally adopted the least misery strategy to select a single optimal solution from the Pareto set.\n","\n","By contrast, Zheng, et al. utilized MOEA as the optimizer to recommend Kaggle datasets to students for the projects by considering the item utility from the perspective of both students and instructors. They took advantage of the multi-criteria rating vectors and expectation vectors to compute the item utility in view of students and instructors by using a utility-based multi-criteria recommendation framework. Weighed sum is used to aggregate the two utilities (i.e., from perspective of students and instructors) to produce the ranking score which can be applied to sort and rank items. MOEA was applied to consider the student and instructor satisfactions, as well as the recommendation performance as the multiple metrics. A TOPSIS based method was used to select a single optimal solution from the Pareto set generated by MOEA. The experimental results can demonstrate that the model could improve the instructor’s satisfaction at a limited loss on the recommendation performance.\n","\n","### 4. Multi-Task Recommender Systems\n","\n","The multi-task recommender systems refer to the recommender system which optimize multiple tasks through a joint learning process. Particularly, there are usually some common or shared representations in multi-task recommender systems, such as the shared latent-factors or embedding layers in the neural network models. Note that, multi-task recommender systems are not limited to the models using neural networks. Some work utilizing matrix factorization can optimize both rating prediction and ranking tasks by sharing the user and item latent factors. The goal is to improve multiple tasks by a joint learning process. However, the improvement is dependent with the correlation of the tasks and the power of the shared representations.\n","\n","Neural-based **multi-task learning** has been successfully used in many real-world large-scale applications such as recommendation systems. For example, in movie recommendations, beyond providing users movies which they tend to purchase and watch, the system might also optimize for users liking the movies afterwards. With multi-task learning, we aim to build a single model that learns these multiple goals and tasks simultaneously.\n","\n","In multi-task recommender systems, most of the work utilized the joint learning process which is in shape of the weighed sum of the scalarization method. However, researchers may just assign a learning rate to each loss function without guaranteeing the sum of the weights is one. In this case, it is not guaranteed that researchers can find a Pareto set, though a single solution may still be Pareto optimal. Furthermore, the researchers may just tune up the learning and regularization rates to find a better solution than the baseline. According to the instructions in MOO, trying different weights to produce a Pareto set and selecting an optimal solution from the set should be formal way, if the preferences of the decision maker is not available."]}]}